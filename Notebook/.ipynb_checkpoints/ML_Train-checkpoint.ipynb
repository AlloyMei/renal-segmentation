{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from Source.util import getPathsToVisit\n",
    "from Source.ipythonWidgets import overlayViewer, reconViewer\n",
    "from Source.featureExtractor import extract_features, extract_features_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 9\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/01\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/02\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/04\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/05\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/06\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/07\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/08\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/10\n",
      "/Users/umityoruk/Documents/PythonDev/FinalSegmentation/ML/Train/11\n"
     ]
    }
   ],
   "source": [
    "pathsToVisit = getPathsToVisit('../ML/Train')\n",
    "print('Number of subjects:', len(pathsToVisit))\n",
    "\n",
    "features_train = []\n",
    "labels_train = []\n",
    "for subjectPath in pathsToVisit:\n",
    "    print(subjectPath)\n",
    "\n",
    "    # Load the dataset.\n",
    "    reconPath = os.path.join(subjectPath, 'recon4d.hdf5')\n",
    "    with h5py.File(reconPath) as f:\n",
    "        spacing = np.array(f['spacing'])\n",
    "        temp_res = np.array(f['temp_res']).astype(np.float)/1000\n",
    "        recon = np.array(f['recon'])\n",
    "    ss_f = [2, 2, 2, 1]  # Subsampling factor [x,y,z,t]\n",
    "\n",
    "    recon = recon[::ss_f[0],::ss_f[1],::ss_f[2],::ss_f[3]]\n",
    "    spacing = np.array([ss_f[0],ss_f[1],ss_f[2]])*spacing\n",
    "    nx, ny, nz, nt = recon.shape\n",
    "    \n",
    "    # Load the labels.\n",
    "    labelsPath = os.path.join(subjectPath, 'labels.hdf5')\n",
    "    with h5py.File(labelsPath) as f:\n",
    "        labels3d = np.array(f['labels'])\n",
    "    labels3d = labels3d[::ss_f[0],::ss_f[1],::ss_f[2]]\n",
    "    \n",
    "    time_stamps = np.arange(nt)*temp_res\n",
    "    features, labels = extract_features_and_labels(recon, spacing, time_stamps, labels3d)\n",
    "    features_train.append(features)\n",
    "    labels_train.append(labels)\n",
    "\n",
    "features_train = np.vstack(features_train)\n",
    "labels_train = np.hstack(labels_train)\n",
    "\n",
    "outputPath = os.path.join('..', 'ML', 'train.hdf5')\n",
    "with h5py.File(outputPath, 'w') as f:\n",
    "    dset = f.create_dataset('features', data=features_train, compression='gzip')\n",
    "    dset = f.create_dataset('labels', data=labels_train, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputPath = os.path.join('..', 'ML', 'train.hdf5')\n",
    "with h5py.File(inputPath) as f:\n",
    "    features_all = np.array(f['features'])\n",
    "    labels_all = np.array(f['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019070, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a small number of samples to speed up training\n",
    "num_select = 10000\n",
    "np.random.seed(42)\n",
    "idx_sel = np.random.choice(np.arange(features_all.shape[0]), num_select)\n",
    "features_sel = features_all[idx_sel,:]\n",
    "labels_sel = labels_all[idx_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3228\n",
      "          1       1.00      1.00      1.00      1060\n",
      "          2       1.00      1.00      1.00       325\n",
      "          3       1.00      1.00      1.00       387\n",
      "\n",
      "avg / total       1.00      1.00      1.00      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.87      0.93      0.90      1054\n",
      "          2       0.71      0.58      0.64       308\n",
      "          3       0.89      0.85      0.87       380\n",
      "\n",
      "avg / total       0.95      0.95      0.95      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If features change, run GridSearch again (see cells below) to identify the best hyperparameters.\n",
    "\n",
    "# Look at the performance of the classifier on the full feature set.\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_sel, labels_sel, test_size=0.5, random_state=42)\n",
    "\n",
    "X_mean = np.mean(X_train, axis=0, keepdims=True)\n",
    "X_std = np.std(X_train, axis=0, keepdims=True)\n",
    "X_train -= X_mean\n",
    "X_train /= X_std\n",
    "X_test -= X_mean\n",
    "X_test /= X_std\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "pred_train = classifier.predict(X_train)\n",
    "pred_test = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_train, pred_train))\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.65      0.86      0.74      1054\n",
      "          2       0.32      0.21      0.25       308\n",
      "          3       0.36      0.14      0.20       380\n",
      "\n",
      "avg / total       0.83      0.86      0.84      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.74      0.84      0.79      1054\n",
      "          2       0.33      0.23      0.27       308\n",
      "          3       0.84      0.73      0.78       380\n",
      "\n",
      "avg / total       0.89      0.90      0.89      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.77      0.90      0.83      1054\n",
      "          2       0.43      0.22      0.29       308\n",
      "          3       0.91      0.82      0.86       380\n",
      "\n",
      "avg / total       0.91      0.92      0.91      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.81      0.89      0.85      1054\n",
      "          2       0.53      0.38      0.44       308\n",
      "          3       0.88      0.85      0.86       380\n",
      "\n",
      "avg / total       0.92      0.93      0.92      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.87      0.90      0.88      1054\n",
      "          2       0.62      0.58      0.60       308\n",
      "          3       0.90      0.86      0.88       380\n",
      "\n",
      "avg / total       0.94      0.94      0.94      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.88      0.92      0.90      1054\n",
      "          2       0.69      0.61      0.65       308\n",
      "          3       0.89      0.86      0.87       380\n",
      "\n",
      "avg / total       0.95      0.95      0.95      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.87      0.93      0.90      1054\n",
      "          2       0.72      0.58      0.64       308\n",
      "          3       0.89      0.84      0.86       380\n",
      "\n",
      "avg / total       0.95      0.95      0.95      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train models for different feature lengths (needed for shorter datasets)\n",
    "# The first 6 features are signal samples at t = 0, 30, 60, 90, 120, 150 seconds.\n",
    "# The next feature is depth of voxel from renal surface.\n",
    "\n",
    "for num_feats in range(1,8):\n",
    "#     classifier = SVC(C=100, gamma=0.1)\n",
    "    classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Split the dataset in two equal parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features_sel[:,-num_feats:], labels_sel, test_size=0.5, random_state=42)\n",
    "\n",
    "    X_mean = np.mean(X_train, axis=0, keepdims=True)\n",
    "    X_std = np.std(X_train, axis=0, keepdims=True)\n",
    "    X_train -= X_mean\n",
    "    X_train /= X_std\n",
    "    X_test -= X_mean\n",
    "    X_test /= X_std\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred_train = classifier.predict(X_train)\n",
    "    pred_test = classifier.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, pred_test))\n",
    "    \n",
    "    # Save the model\n",
    "    model = {}\n",
    "    model['classifier'] = classifier\n",
    "    model['mean'] = X_mean\n",
    "    model['std'] = X_std\n",
    "\n",
    "    model_filename = os.path.join(os.getcwd(), '../Models', 'subsegment_model_f' + str(num_feats) + '.pkl')\n",
    "\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the last model to check contents\n",
    "with open(model_filename, 'rb') as f:\n",
    "    model2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "             verbose=0, warm_start=False),\n",
       " 'mean': array([[ -2.99793607e-03,   6.31695977e-04,   3.14344195e-04,\n",
       "          -4.90479065e-03,  -7.97483234e-03,  -1.06558284e-02,\n",
       "           1.71025663e+00]]),\n",
       " 'std': array([[ 0.9951846 ,  1.00152891,  1.00201283,  0.99494654,  0.99293985,\n",
       "          0.98759974,  2.92541207]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search example for hyperparameter optimization (Random Forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 1000}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.904 (+/-0.014) for {'n_estimators': 10}\n",
      "0.903 (+/-0.014) for {'n_estimators': 100}\n",
      "0.905 (+/-0.016) for {'n_estimators': 1000}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3258\n",
      "          1       0.76      0.91      0.83      1054\n",
      "          2       0.44      0.22      0.29       308\n",
      "          3       0.91      0.81      0.85       380\n",
      "\n",
      "avg / total       0.91      0.92      0.91      5000\n",
      "\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full data set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6486\n",
      "          1       0.87      0.95      0.91      2114\n",
      "          2       0.82      0.62      0.71       633\n",
      "          3       0.96      0.90      0.93       767\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_feats = 7\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_sel[:,-num_feats:], labels_sel, test_size=0.5, random_state=42)\n",
    "X_mean = np.mean(X_train, axis=0, keepdims=True)\n",
    "X_std = np.std(X_train, axis=0, keepdims=True)\n",
    "X_train -= X_mean\n",
    "X_train /= X_std\n",
    "X_test -= X_mean\n",
    "X_test /= X_std\n",
    "X_all = np.vstack((X_train, X_test))\n",
    "y_all = np.hstack((y_train, y_test))\n",
    "\n",
    "tuned_parameters = [{'n_estimators': [10, 100, 1000]}]\n",
    "\n",
    "scores = ['f1']\n",
    "# scores = ['f1', 'precision', 'recall']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(RandomForestClassifier(n_estimators=10), tuned_parameters, cv=5, \n",
    "                           scoring='%s_weighted' % score)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        for params, mean_score, scores in clf.grid_scores_:\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean_score, scores.std() * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full data set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_all, clf.predict(X_all)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Grid Search example for hyperparameter optimization (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'gamma': 0.1, 'kernel': 'rbf', 'C': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.906 (+/-0.025) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 1}\n",
      "0.937 (+/-0.012) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 1}\n",
      "0.937 (+/-0.015) for {'gamma': 1, 'kernel': 'rbf', 'C': 1}\n",
      "0.937 (+/-0.011) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 10}\n",
      "0.938 (+/-0.012) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 10}\n",
      "0.929 (+/-0.012) for {'gamma': 1, 'kernel': 'rbf', 'C': 10}\n",
      "0.938 (+/-0.012) for {'gamma': 0.01, 'kernel': 'rbf', 'C': 100}\n",
      "0.941 (+/-0.010) for {'gamma': 0.1, 'kernel': 'rbf', 'C': 100}\n",
      "0.920 (+/-0.018) for {'gamma': 1, 'kernel': 'rbf', 'C': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3297\n",
      "          1       0.87      0.94      0.91      1037\n",
      "          2       0.76      0.61      0.68       304\n",
      "          3       0.93      0.87      0.90       362\n",
      "\n",
      "avg / total       0.95      0.95      0.95      5000\n",
      "\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full data set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      6486\n",
      "          1       0.87      0.96      0.91      2114\n",
      "          2       0.80      0.61      0.69       633\n",
      "          3       0.93      0.86      0.89       767\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_sel, labels_sel, test_size=0.5, random_state=3)\n",
    "X_mean = np.mean(X_train, axis=0, keepdims=True)\n",
    "X_std = np.std(X_train, axis=0, keepdims=True)\n",
    "X_train -= X_mean\n",
    "X_train /= X_std\n",
    "X_test -= X_mean\n",
    "X_test /= X_std\n",
    "X_all = np.vstack((X_train, X_test))\n",
    "y_all = np.hstack((y_train, y_test))\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.01, 0.1, 1],\n",
    "                     'C': [1, 10, 100]},\n",
    "#                     {'kernel': ['linear'], 'C': [1, 10]},\n",
    "                   ]\n",
    "scores = ['f1']\n",
    "# scores = ['f1', 'precision', 'recall']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        if 'custom' in score:\n",
    "            clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, scoring=scorer)\n",
    "        else:\n",
    "            clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5, \n",
    "                               scoring='%s_weighted' % score)\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        for params, mean_score, scores in clf.grid_scores_:\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean_score, scores.std() * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full data set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_all, clf.predict(X_all)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
